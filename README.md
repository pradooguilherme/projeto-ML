# üß† Modelo supervisionado de reranqueamento (LambdaRank + BM25)

Este projeto tem como objetivo treinar um modelo supervisionado de **reranqueamento** baseado em **Learning to Rank (LTR)**, combinando features derivadas do **BM25** e outras m√©tricas textuais para ordenar documentos de acordo com consultas.

---

## üìö Conjunto de documentos e consultas

O dataset utilizado √© o **BBC News**, composto por aproximadamente **2.200 documentos** categorizados em cinco temas principais:

- **Business**
- **Entertainment**
- **Politics**
- **Sport**
- **Tech**

Para cada categoria, foram geradas **6 consultas**, totalizando **30 consultas**. Essas consultas serviram como base para a constru√ß√£o do conjunto de treinamento do modelo.

---

## ‚öôÔ∏è Cria√ß√£o do conjunto de treinamento

Inicialmente, realizamos uma **divis√£o holdout** na propor√ß√£o de **70% para treinamento** e **30% para teste**.

Os dados de entrada do modelo seguem o formato **query-documento**, onde cada linha representa um documento retornado por uma consulta e suas respectivas features.

A gera√ß√£o desse conjunto foi feita atrav√©s de buscas no **Elasticsearch**, que utiliza o **BM25** como algoritmo padr√£o de ranqueamento.  
Para cada consulta, coletamos os **50 melhores resultados**, registrando as seguintes features:

- **Pontua√ß√£o BM25** do documento  
- **N√∫mero de palavras da consulta presentes no t√≠tulo**  
- **N√∫mero de palavras da consulta presentes no corpo do texto**

O resultado foi um **dataset supervisionado** de pares query-documento com tr√™s features num√©ricas por amostra.

---

## üß† Treinamento do modelo

O modelo foi treinado utilizando o algoritmo **LambdaRank**, implementado na biblioteca **LightGBM**.  
Esse algoritmo aprende a ordenar documentos com base em **r√≥tulos de relev√¢ncia supervisionados**.

O r√≥tulo de relev√¢ncia foi definido como bin√°rio:

- **1**: documento pertence √† mesma categoria da consulta  
- **0**: documento pertence a uma categoria diferente  

---

## üìä Resultados

No conjunto de teste, o modelo **LambdaRank** obteve um **NDCG@10 m√©dio de 0.6576**, representando um **ganho relativo de aproximadamente 4%** em rela√ß√£o √† baseline baseada exclusivamente no BM25 (**NDCG@10 = 0.6158**).

---

## üöÄ Conclus√£o e pr√≥ximos passos

Apesar do **tamanho reduzido do dataset** e do **n√∫mero limitado de features**, o modelo apresentou uma **melhora significativa** em rela√ß√£o ao BM25 puro.

Os resultados indicam que o uso de **Learning to Rank** √© promissor mesmo em cen√°rios simples.

**Pr√≥ximos passos:**

- Incorporar **novas features sem√¢nticas** (ex: embeddings)  
- Avaliar desempenho em **cole√ß√µes maiores** e com **consultas reais**  

---

## üß∞ Tecnologias utilizadas

- Python  
- Elasticsearch  
- LightGBM  
- NumPy  
- Pandas
